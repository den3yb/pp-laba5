{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas \n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "path = \"C:\\\\Proganiy\\\\pp-laba3\\\\annotation.csv\"\n",
    "print(russian_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Оценка Kоличество слов                                     Текст рецензии\n",
      "0         1            1853  11 марта этого года переводила 145 в Германию(...\n",
      "1         1            4278  В пятницу, 22 апреля 2022 г. Сбербанк заблокир...\n",
      "2         1            2035  Здравствуйте. Перед оформлением досудебной пре...\n",
      "3         1            3503  Я являюсь клиентом Сбербанка уже более десяти ...\n",
      "4         1            3340  Призываю предпринимателей подумать дважды, пре...\n",
      "...     ...             ...                                                ...\n",
      "2995      5             304  Сегодня хочу рассказать о Сбербанке. В этом пр...\n",
      "2996      5             863  Банк Сбербанк - это прекрасное финансовое учре...\n",
      "2997      5             979  Пользуюсь сбербанком сколько себя помню, зарпл...\n",
      "2998      5            2084  Я не сразу научилась пользоваться кредитной сб...\n",
      "2999      5             777  Пользуюсь сбербанком давно, никаких нарекании ...\n",
      "\n",
      "[3000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def create_ann(annatation: str) -> pandas.DataFrame:\n",
    "\n",
    "    \"\"\"Создаёт датафрейм по пути аннатации\"\"\"\n",
    "\n",
    "    frame = pandas.DataFrame(columns =[\"Оценка\",\"Kоличество слов\",\"Текст рецензии\"])\n",
    "    ann_temp = open(annatation, \"r\", encoding=\"utf-8\")\n",
    "    for otzv in ann_temp.readlines():\n",
    "        mas_otzv = otzv.split(\",\")\n",
    "        otzv_temp = open(mas_otzv[0],\"r\",encoding=\"utf-8\")\n",
    "        otzv_text = \" \".join(otzv_temp)\n",
    "        row = pandas.Series({\"Оценка\": int(mas_otzv[2]),\"Kоличество слов\": len(otzv_text), \"Текст рецензии\": otzv_text})\n",
    "        new_row = pandas.DataFrame([row], columns=frame.columns)\n",
    "        frame = pandas.concat([frame, new_row], ignore_index=True)\n",
    "    frame.dropna()\n",
    "    return frame\n",
    "\n",
    "data = create_ann(path)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Оценка Kоличество слов                                     Текст рецензии\n",
      "0         1            1853   марта этого года переводила  в Германиюденежн...\n",
      "1         1            4278  В пятницу  апреля  г Сбербанк заблокировал мою...\n",
      "2         1            2035  Здравствуйте Перед оформлением досудебной прет...\n",
      "3         1            3503  Я являюсь клиентом Сбербанка уже более десяти ...\n",
      "4         1            3340  Призываю предпринимателей подумать дважды преж...\n",
      "...     ...             ...                                                ...\n",
      "2995      5             304  Сегодня хочу рассказать о Сбербанке В этом при...\n",
      "2996      5             863  Банк Сбербанк  это прекрасное финансовое учреж...\n",
      "2997      5             979  Пользуюсь сбербанком сколько себя помню зарпла...\n",
      "2998      5            2084  Я не сразу научилась пользоваться кредитной сб...\n",
      "2999      5             777  Пользуюсь сбербанком давно никаких нарекании н...\n",
      "\n",
      "[3000 rows x 3 columns]\n",
      "     Оценка Kоличество слов                                     Текст рецензии\n",
      "0         1            1853  [ , март,  , этот,  , год,  , переводить,   , ...\n",
      "1         1            4278  [в,  , пятница,   , апрель,   , г,  , сбербанк...\n",
      "2         1            2035  [здравствовать,  , перед,  , оформление,  , до...\n",
      "3         1            3503  [я,  , являться,  , клиент,  , сбербанк,  , уж...\n",
      "4         1            3340  [призывать,  , предприниматель,  , подумать,  ...\n",
      "...     ...             ...                                                ...\n",
      "2995      5             304  [сегодня,  , хотеть,  , рассказывать,  , о,  ,...\n",
      "2996      5             863  [банк,  , сбербанк,   , это,  , прекрасный,  ,...\n",
      "2997      5             979  [пользоваться,  , сбербанк,  , сколько,  , себ...\n",
      "2998      5            2084  [я,  , не,  , сразу,  , научаться,  , пользова...\n",
      "2999      5             777  [пользоваться,  , сбербанк,  , давно,  , никак...\n",
      "\n",
      "[3000 rows x 3 columns]\n",
      "     Оценка Kоличество слов                                     Текст рецензии\n",
      "0         1            1853    март   этот   год   переводить    в   герман...\n",
      "1         1            4278  в   пятница    апрель    г   сбербанк   заблок...\n",
      "2         1            2035  здравствовать   перед   оформление   досудебны...\n",
      "3         1            3503  я   являться   клиент   сбербанк   уже   много...\n",
      "4         1            3340  призывать   предприниматель   подумать   дважд...\n",
      "...     ...             ...                                                ...\n",
      "2995      5             304  сегодня   хотеть   рассказывать   о   сбербанк...\n",
      "2996      5             863  банк   сбербанк    это   прекрасный   финансов...\n",
      "2997      5             979  пользоваться   сбербанк   сколько   себя   пом...\n",
      "2998      5            2084  я   не   сразу   научаться   пользоваться   кр...\n",
      "2999      5             777  пользоваться   сбербанк   давно   никакой   на...\n",
      "\n",
      "[3000 rows x 3 columns]\n",
      "     Оценка Kоличество слов                                     Текст рецензии\n",
      "0         1            1853  [март, этот, год, переводить, в, германиюденеж...\n",
      "1         1            4278  [в, пятница, апрель, г, сбербанк, заблокироват...\n",
      "2         1            2035  [здравствовать, перед, оформление, досудебный,...\n",
      "3         1            3503  [я, являться, клиент, сбербанк, уже, много, де...\n",
      "4         1            3340  [призывать, предприниматель, подумать, дважды,...\n",
      "...     ...             ...                                                ...\n",
      "2995      5             304  [сегодня, хотеть, рассказывать, о, сбербанк, в...\n",
      "2996      5             863  [банк, сбербанк, это, прекрасный, финансовый, ...\n",
      "2997      5             979  [пользоваться, сбербанк, сколько, себя, помнит...\n",
      "2998      5            2084  [я, не, сразу, научаться, пользоваться, кредит...\n",
      "2999      5             777  [пользоваться, сбербанк, давно, никакой, нарек...\n",
      "\n",
      "[3000 rows x 3 columns]\n",
      "     Оценка Kоличество слов                                     Текст рецензии\n",
      "0         1            1853  март этот год переводить в германиюденежный ср...\n",
      "1         1            4278  в пятница апрель г сбербанк заблокировать мой ...\n",
      "2         1            2035  здравствовать перед оформление досудебный прет...\n",
      "3         1            3503  я являться клиент сбербанк уже много десять го...\n",
      "4         1            3340  призывать предприниматель подумать дважды преж...\n",
      "...     ...             ...                                                ...\n",
      "2995      5             304  сегодня хотеть рассказывать о сбербанк в это п...\n",
      "2996      5             863  банк сбербанк это прекрасный финансовый учрежд...\n",
      "2997      5             979  пользоваться сбербанк сколько себя помнить зар...\n",
      "2998      5            2084  я не сразу научаться пользоваться кредитный сб...\n",
      "2999      5             777  пользоваться сбербанк давно никакой нарекание ...\n",
      "\n",
      "[3000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def clean (frame: pandas.DataFrame) -> pandas.DataFrame:\n",
    "    frame[\"Текст рецензии\"] = frame[\"Текст рецензии\"].apply(delete_punc)\n",
    "    print(frame)\n",
    "    frame[\"Текст рецензии\"] = frame[\"Текст рецензии\"].apply(Mystem().lemmatize)\n",
    "    print(frame)\n",
    "    frame[\"Текст рецензии\"] = frame[\"Текст рецензии\"].apply(lambda x: ' '.join(x))\n",
    "    print(frame)\n",
    "    frame[\"Текст рецензии\"] = frame[\"Текст рецензии\"].apply(word_tokenize)\n",
    "    print(frame)\n",
    "    frame[\"Текст рецензии\"] = frame[\"Текст рецензии\"].apply(lambda x: ' '.join(x))\n",
    "    return frame\n",
    "\n",
    "def delete_punc(strings: str) -> str:\n",
    "    punc = '''!()-[]{};:'\",<>./?@#$%^&*~1234567890'''\n",
    "    for char in strings:\n",
    "        if char in punc:\n",
    "            strings = strings.replace(char, \"\")\n",
    "    return strings\n",
    "\n",
    "data = clean(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 10000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = 10000\n",
    "cv = CountVectorizer(max_features=max_words)\n",
    "sparse_matrix = cv.fit_transform(data['Текст рецензии']).toarray()\n",
    "sparse_matrix.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(sparse_matrix, np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mОценка\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m      2\u001b[0m x_train \u001b[38;5;241m=\u001b[39m Variable(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(x_train))\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m----> 3\u001b[0m y_train \u001b[38;5;241m=\u001b[39m Variable(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mlong()\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(sparse_matrix, np.array(data['Оценка']))\n",
    "x_train = Variable(torch.from_numpy(x_train)).float()\n",
    "y_train = Variable(torch.from_numpy(y_train)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 22\u001b[0m\n\u001b[0;32m     18\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(params\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters() , lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m     21\u001b[0m x_train \u001b[38;5;241m=\u001b[39m Variable(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(x_train))\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m---> 22\u001b[0m y_train \u001b[38;5;241m=\u001b[39m Variable(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mlong()\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear1 = nn.Linear(10000, 1000)\n",
    "        self.linear2 = nn.Linear(1000, 100)\n",
    "        self.linear3 = nn.Linear(100, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "model = LogisticRegression()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters() , lr=0.01)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(x_train)\n\u001b[1;32m----> 7\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m loss_values\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m      9\u001b[0m pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(y_pred, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39meq(y_train)\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3052\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 20\n",
    "model.train()\n",
    "loss_values = []\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    loss_values.append(loss.item())\n",
    "    pred = torch.max(y_pred, 1)[1].eq(y_train).sum()\n",
    "    acc = pred * 100.0 / len(x_train)\n",
    "    print('Epoch: {}, Loss: {}, Accuracy: {}%'.format(epoch+1, loss.item(), acc.numpy()))\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(x_test)\n",
    "    loss = criterion(y_pred, y_test)\n",
    "    pred = torch.max(y_pred, 1)[1].eq(y_test).sum()\n",
    "    print (\"Accuracy : {}%\".format(100*pred/len(x_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
