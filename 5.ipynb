{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch._custom_ops'; 'torch' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Proganiy\\Python\\Lib\\site-packages\\torchvision\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodulefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Proganiy\\Python\\Lib\\site-packages\\torchvision\\_meta_registrations.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_custom_ops\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibrary\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Ensure that torch.ops.torchvision is visible\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch._custom_ops'; 'torch' is not a package"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "\n",
    "import pandas \n",
    "import string\n",
    "import matplotlib.pyplot\n",
    "import re\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path = \"C:\\\\Proganiy\\\\pp-laba3\\\\annotation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Оценка Kоличество слов                                     Текст рецензии\n",
      "0       1            1853  11 марта этого года переводила 145 в Германию(...\n",
      "1       1            4278  В пятницу, 22 апреля 2022 г. Сбербанк заблокир...\n",
      "2       1            2035  Здравствуйте. Перед оформлением досудебной пре...\n",
      "3       1            3503  Я являюсь клиентом Сбербанка уже более десяти ...\n",
      "4       1            3340  Призываю предпринимателей подумать дважды, пре...\n",
      "..    ...             ...                                                ...\n",
      "95      1            1486  Банк №1 в России, который не в состоянии помоч...\n",
      "96      1             442  Привязали мой номер телефона к несуществующей ...\n",
      "97      1             409  Я коротко :) график с 8:30 до 17:30 :). Для ко...\n",
      "98      1            1182  При оформлении кредита присылают утвердительну...\n",
      "99      1            1492  Подарок от сбербанка!!!11.03.21 у меня был ден...\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def create_ann(annatation: str) -> pandas.DataFrame:\n",
    "\n",
    "    \"\"\"Создаёт датафрейм по пути аннатации\"\"\"\n",
    "\n",
    "    frame = pandas.DataFrame(columns =[\"Оценка\",\"Kоличество слов\",\"Текст рецензии\"])\n",
    "    ann_temp = open(annatation, \"r\", encoding=\"utf-8\")\n",
    "    for otzv in ann_temp.readlines():\n",
    "        mas_otzv = otzv.split(\",\")\n",
    "        otzv_temp = open(mas_otzv[0],\"r\",encoding=\"utf-8\")\n",
    "        otzv_text = \" \".join(otzv_temp)\n",
    "        row = pandas.Series({\"Оценка\": int(mas_otzv[2]),\"Kоличество слов\": len(otzv_text), \"Текст рецензии\": otzv_text})\n",
    "        new_row = pandas.DataFrame([row], columns=frame.columns)\n",
    "        frame = pandas.concat([frame, new_row], ignore_index=True)\n",
    "    frame.dropna()\n",
    "    return frame\n",
    "\n",
    "data = create_ann(path)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    Оценка Kоличество слов                                     Текст рецензии\n",
      "0       1            1853       март     этот     год     переводить     ...\n",
      "1       1            4278  в     пятница         апрель          г      с...\n",
      "2       1            2035  здравствовать      перед     оформление     до...\n",
      "3       1            3503  я     являться     клиент     сбербанк     уже...\n",
      "4       1            3340  призывать     предприниматель     подумать    ...\n",
      "..    ...             ...                                                ...\n",
      "95      1            1486  банк        в     россия      который     не  ...\n",
      "96      1             442  привязывать     мой     номер     телефон     ...\n",
      "97      1             409  я     короче        график     с          до  ...\n",
      "98      1            1182  при     оформление     кредит     присылать   ...\n",
      "99      1            1492  подарок     от     сбербанк                у  ...\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "   Оценка Kоличество слов                                     Текст рецензии\n",
      "0       1            1853       март     этот     год     переводить     ...\n",
      "1       1            4278  в     пятница         апрель          г      с...\n",
      "2       1            2035  здравствовать      перед     оформление     до...\n",
      "3       1            3503  я     являться     клиент     сбербанк     уже...\n",
      "4       1            3340  призывать     предприниматель     подумать    ...\n",
      "..    ...             ...                                                ...\n",
      "95      1            1486  банк        в     россия      который     не  ...\n",
      "96      1             442  привязывать     мой     номер     телефон     ...\n",
      "97      1             409  я     короче        график     с          до  ...\n",
      "98      1            1182  при     оформление     кредит     присылать   ...\n",
      "99      1            1492  подарок     от     сбербанк                у  ...\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def clean (frame: pandas.DataFrame) -> pandas.DataFrame:\n",
    "    remove_non_alphabets =lambda x: re.sub(r'[^а-яА-Я]',' ',x)\n",
    "\n",
    "    frame[\"Текст рецензии\"] = frame[\"Текст рецензии\"].apply(remove_non_alphabets)\n",
    "    frame[\"Текст рецензии\"] = frame[\"Текст рецензии\"].apply(Mystem().lemmatize)\n",
    "    frame[\"Текст рецензии\"] = frame[\"Текст рецензии\"].apply(lambda x: ' '.join(x))\n",
    "    print('3', frame)\n",
    "    return frame\n",
    "\n",
    "data = clean(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CountVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m max_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[1;32m----> 2\u001b[0m cv \u001b[38;5;241m=\u001b[39m \u001b[43mCountVectorizer\u001b[49m(max_features\u001b[38;5;241m=\u001b[39mmax_words, stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrussian\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m sparse_matrix \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mfit_transform(frame[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mТекст рецензии\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m      5\u001b[0m sparse_matrix\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CountVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "max_words = 10000\n",
    "cv = CountVectorizer(max_features=max_words, stop_words='russian')\n",
    "sparse_matrix = cv.fit_transform(frame[\"Текст рецензии\"]).toarray()\n",
    "\n",
    "sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(sparse_matrix, np.array(frame[\"Оценка\"]))\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear1 = nn.Linear(10000, 1000)\n",
    "        self.linear2 = nn.Linear(1000, 100)\n",
    "        self.linear3 = nn.Linear(100, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "model = LogisticRegression()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters() , lr=0.01)\n",
    "\n",
    "\n",
    "x_train = Variable(torch.from_numpy(x_train)).float()\n",
    "y_train = Variable(torch.from_numpy(y_train)).long()\n",
    "x_test = Variable(torch.from_numpy(x_test)).float()\n",
    "y_test = Variable(torch.from_numpy(y_test)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "epochs = 20\n",
    "model.train()\n",
    "loss_values = []\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    loss_values.append(loss.item())\n",
    "    pred = torch.max(y_pred, 1)[1].eq(y_train).sum()\n",
    "    acc = pred * 100.0 / len(x_train)\n",
    "    print('Epoch: {}, Loss: {}, Accuracy: {}%'.format(epoch+1, loss.item(), acc.numpy()))\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(x_test)\n",
    "    loss = criterion(y_pred, y_test)\n",
    "    pred = torch.max(y_pred, 1)[1].eq(y_test).sum()\n",
    "    print (\"Accuracy : {}%\".format(100*pred/len(x_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
